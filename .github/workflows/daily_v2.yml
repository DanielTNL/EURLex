name: Pipeline v2 (daily)

on:
  schedule:
    # GitHub Actions cron is UTC. 06:00 UTC = 08:00 Europe/Amsterdam (CEST).
    - cron: "0 6 * * *"
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: daily-v2
  cancel-in-progress: false

env:
  TZ: Europe/Amsterdam

jobs:
  run:
    runs-on: ubuntu-latest
    # (Optional) hardcode here if you don't want to touch config_v2.yaml:
    # env:
    #   REVALIDATE_URL: "https://your-site.com/api/revalidate?secret=XYZ"
    #   REVALIDATE_PATHS: '["/","/live"]'

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (best-effort)
        run: |
          python -V
          pip install -r requirements.txt || true
          pip install requests python-dateutil beautifulsoup4 lxml pyyaml orjson jsonschema jq || true

      # 1) Discover laatste 24 uur (alle bronnen uit sources_v2.yaml)
      - name: Daily discover (last 24h)
        run: |
          if [ -f sources_v2.yaml ]; then
            python workers/weekly_discover.py --window 1d --sources sources_v2.yaml --config config_v2.yaml
          else
            python workers/weekly_discover.py --window 1d --config config_v2.yaml
          fi

      # 2) Verwerk documenten (samenvattingen e.d.)
      - name: Process documents
        run: |
          python workers/process_document.py --from state/latest_discovery.json --config config_v2.yaml --limit 50

      # 3) Bouw rolling timeline (7 dagen is prettig voor website)
      - name: Build timeline (rolling 7d)
        run: |
          python workers/build_timeline.py --window 7d --config config_v2.yaml

      # 4) Daily digest (MD + JSON → voor nieuwsbrief/website)
      - name: Build daily digest
        run: |
          python workers/build_daily_digest.py --hours 24

      # 5) Build site payload (jouw bestaande site builder of minimale fallback)
      - name: Build site payload
        run: |
          if [ -f build_site_data.py ]; then
            python build_site_data.py || true
          else
            python workers/build_site_data_v2.py
          fi

      # 6) Publiceer bridge: v2 → legacy paden die de front-end leest
      - name: Publish site bridge (v2 → legacy)
        run: |
          python workers/publish_site_bridge.py

      # Inspectie in logs
      - name: Show outputs (ls + head)
        run: |
          echo "== outputs/docs ==" && ls -lah outputs/docs || true
          echo "== outputs/timelines ==" && ls -lah outputs/timelines || true
          echo "== reports/daily ==" && ls -lah reports/daily || true
          echo "== docs/digests ==" && ls -lah docs/digests || true
          echo "== docs/data ==" && ls -lah docs/data || true
          echo "== docs/site ==" && ls -lah docs/site || true
          echo "== docs root json ==" && ls -lah docs/*.json || true
          for f in outputs/docs/*.ndjson; do echo "---- $f"; head -n 2 "$f" || true; done
          for f in outputs/timelines/*.json; do echo "---- $f"; head -n 40 "$f" || true; done

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: daily-v2-data
          path: |
            outputs/docs/*.ndjson
            outputs/timelines/*.json
            reports/daily/*.md
            docs/digests/*.json
            docs/data/*.json
            docs/*.json
            docs/site/*.json
          if-no-files-found: warn

      - name: Commit results back to main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add outputs/docs outputs/timelines reports/daily docs/digests docs/data docs/site docs/*.json || true
          git commit -m "daily pipeline v2 $(date -u +'%F %T') [auto]" || echo "No changes to commit"
          git push || true

      # 7) Revalidate website (no GitHub secret; reads from config_v2.yaml or env override)
      - name: Revalidate website (no secret)
        continue-on-error: true
        run: |
          python - <<'PY'
import os, json, sys
import urllib.request
import yaml

# 1) Prefer env if provided literally in the workflow
url = os.getenv("REVALIDATE_URL", "").strip()
paths_env = os.getenv("REVALIDATE_PATHS", "").strip()

# 2) Else read from config_v2.yaml -> site.revalidate_url / site.revalidate_paths
if not url:
    try:
        cfg = yaml.safe_load(open("config_v2.yaml"))
        url = (cfg.get("site") or {}).get("revalidate_url", "")
        default_paths = ["/","/live"]
        paths = (cfg.get("site") or {}).get("revalidate_paths", default_paths)
    except Exception as e:
        print("Could not read config_v2.yaml:", e)
        url, paths = "", ["/","/live"]
else:
    # If REVALIDATE_PATHS env is set, expect JSON array
    try:
        paths = json.loads(paths_env) if paths_env else ["/","/live"]
    except Exception:
        paths = ["/","/live"]

if not url:
    print("No revalidate URL configured. Skipping.")
    sys.exit(0)

payload = json.dumps({"paths": paths}).encode()
req = urllib.request.Request(url, data=payload, headers={"Content-Type":"application/json"}, method="POST")
try:
    with urllib.request.urlopen(req, timeout=20) as r:
        body = r.read().decode()
        print("Revalidate response:", body[:500])
except Exception as e:
    print("Revalidate failed:", e)
PY
